{
    "createdAt": "2025-02-11T10:07:55.864Z",
    "updatedAt": "2025-02-14T11:38:25.272Z",
    "id": "qikSZPuEnLyIlIas",
    "name": "Chat",
    "active": false,
    "nodes": [
        {
            "parameters": {
                "options": {}
            },
            "type": "@n8n/n8n-nodes-langchain.chatTrigger",
            "typeVersion": 1.1,
            "position": [
                0,
                -460
            ],
            "id": "c8b7db34-7455-4567-9034-f338dc8244a7",
            "name": "When chat message received",
            "webhookId": "904638c5-fa9c-4cdf-8ba4-006ab8ec4ab8"
        },
        {
            "parameters": {
                "fieldsToAggregate": {
                    "fieldToAggregate": [
                        {
                            "fieldToAggregate": "document.pageContent"
                        },
                        {
                            "fieldToAggregate": "score"
                        },
                        {
                            "fieldToAggregate": "document.metadata"
                        }
                    ]
                },
                "options": {}
            },
            "type": "n8n-nodes-base.aggregate",
            "typeVersion": 1,
            "position": [
                660,
                -460
            ],
            "id": "b3e46e9b-a5a9-4351-8ec4-5311f3ae208f",
            "name": "Aggregate"
        },
        {
            "parameters": {
                "model": "llama3.2:latest",
                "options": {
                    "temperature": 0
                }
            },
            "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
            "typeVersion": 1,
            "position": [
                900,
                -240
            ],
            "id": "edc78cd3-8df6-43e8-a348-106cd38302a0",
            "name": "Ollama Chat Model",
            "credentials": {
                "ollamaApi": {
                    "id": "x8tzcom7hoqKz8SP",
                    "name": "Local Ollama Account"
                }
            }
        },
        {
            "parameters": {
                "model": "nomic-embed-text:latest"
            },
            "type": "@n8n/n8n-nodes-langchain.embeddingsOllama",
            "typeVersion": 1,
            "position": [
                220,
                -240
            ],
            "id": "8155efb1-adfb-4d87-96b6-155a9549f3f5",
            "name": "Embeddings Ollama",
            "credentials": {
                "ollamaApi": {
                    "id": "x8tzcom7hoqKz8SP",
                    "name": "Local Ollama Account"
                }
            }
        },
        {
            "parameters": {
                "mode": "load",
                "qdrantCollection": {
                    "__rl": true,
                    "value": "",
                    "mode": "id"
                },
                "prompt": "={{ $json.chatInput }}",
                "topK": 5,
                "options": {}
            },
            "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
            "typeVersion": 1,
            "position": [
                260,
                -460
            ],
            "id": "bc7fd74d-9dcf-4066-a247-bda1ce881fcc",
            "name": "Qdrant Vector Store",
            "executeOnce": true,
            "credentials": {
                "qdrantApi": {
                    "id": "iYwMvHCq2EjfOI8e",
                    "name": "Local Qdrant Database"
                }
            }
        },
        {
            "parameters": {
                "promptType": "define",
                "text": "={{ $('When chat message received').item.json.chatInput }}",
                "options": {
                    "systemMessage": "=System\n- Du bist ein hilfreicher Assistent, der die Fragen eines Studenten anhand seiner eigenen Dokumente beantwortest\n- Die Dokumente, welche du nutzen sollst um deine Antwort zu erstellen, werden von der vorherigen Node übergeben. Darin ist jeweils ein Ausschnitt einer Datei enthalten, welche die größte übereinstimmung mit der Query des Users hat.\n- Die Übereinstimmung wird mit einem Score bewertet, je niedriger der Score, desto höher die Wahrscheinlichkeit, dass die gegebene Information wichtig ist\n- Nutze IMMER nur die Dokumente, auf keinen Fall eigenes Wissen oder andere Quellen!\n- Gebe auch mit an, welches Dokument du genutzt hast und welche Zeilen wichtig waren. Nutze hierfür die Metadaten wie \"titel\" und \"lines from: to:\"\n- Erfinde NIEMALS eigene Antworten. Wenn die Dokumente keine relevanten Informationen enthalten, antworte einfach mit \"Ich kann keine Antwort in den zur Verfügung gestellten Dokumenten finden.\"\n\nDokumente:\n1.\n{{ $json.pageContent[0] }}\nScore: {{ $json.score[0] }}\nMetadaten:\ntitel: {{ $json.metadata[0].title }}\nlines:\n  from: {{ $json.metadata[0].loc.lines.from }}\n  to: {{ $json.metadata[0].loc.lines.to }}\n2.\n{{ $json.pageContent[1] }}\nScore: {{ $json.score[1] }}\nMetadaten:\ntitel: {{ $json.metadata[1].title }}\nlines:\n  from: {{ $json.metadata[1].loc.lines.from }}\n  to: {{ $json.metadata[1].loc.lines.to }}\n\n3.\n{{ $json.pageContent[2] }}\nScore: {{ $json.score[2] }}\nMetadaten:\ntitel: {{ $json.metadata[2].title }}\nlines:\n  from: {{ $json.metadata[2].loc.lines.from }}\n  to: {{ $json.metadata[2].loc.lines.to }}\n\n4.\n{{ $json.pageContent[3] }}\nScore: {{ $json.score[3] }}\nMetadaten:\ntitel: {{ $json.metadata[3].title }}\nlines:\n  from: {{ $json.metadata[3].loc.lines.from }}\n  to: {{ $json.metadata[3].loc.lines.to }}\n\nUser:\n{{ $('When chat message received').item.json.chatInput }}"
                }
            },
            "type": "@n8n/n8n-nodes-langchain.agent",
            "typeVersion": 1.7,
            "position": [
                900,
                -460
            ],
            "id": "1e1cf1d4-8c01-4cb8-bf58-556484b21be4",
            "name": "AI Agent",
            "executeOnce": true
        }
    ],
    "connections": {
        "When chat message received": {
            "main": [
                [
                    {
                        "node": "Qdrant Vector Store",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Aggregate": {
            "main": [
                [
                    {
                        "node": "AI Agent",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Ollama Chat Model": {
            "ai_languageModel": [
                [
                    {
                        "node": "AI Agent",
                        "type": "ai_languageModel",
                        "index": 0
                    }
                ]
            ]
        },
        "Embeddings Ollama": {
            "ai_embedding": [
                [
                    {
                        "node": "Qdrant Vector Store",
                        "type": "ai_embedding",
                        "index": 0
                    }
                ]
            ]
        },
        "Qdrant Vector Store": {
            "main": [
                [
                    {
                        "node": "Aggregate",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        }
    },
    "settings": {},
    "staticData": null,
    "meta": {
        "templateCredsSetupCompleted": true,
        "instanceId": "558d88703fb65b2d0e44613bc35916258b0f0bf983c5d4730c00c424b77ca36a"
    },
    "pinData": {},
    "versionId": "37c2aceb-3cbc-4e8a-a4e8-2e023d400486",
    "triggerCount": 0,
    "tags": []
}